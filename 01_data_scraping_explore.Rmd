---
title: "01_data_scraping_explore"
author: "Ziwei Crystal Zang"
date: "10/14/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Objective: Twitter data is used to study COVID-19 related mental health sentiments. In the past, a lot of studies has done on studying social behaviors using the social media data. In this study, we are investigating how COVID-19 is influencing people's mental health through tweets. Since we are working with texts, natural language processing and text analysis is be used to clean the text data and tokenize words that are related to users' sentiments that reflects the status of mental health. Sentiment analysis is proposed to associate words with sentiments such as positive, negative, and neutral.  

Resource
Rtweet: https://github.com/ropensci/rtweet

```{r}
for (pkg in c("psych", "ggplot2", "dplyr", "twitteR", "tidytext", "tidyverse", "rtweet")) {
  library(pkg, character.only = TRUE)
}

api_key <- "eV0nQh8tFwJLF6JCf0SzGghi5"
api_secret_key <- "BO2cXph7xRojBes9tcg9uJaOrcDypRYxSf7abMe5Wrx6OmS8Pk"
bearer_token <- "AAAAAAAAAAAAAAAAAAAAAM5FIwEAAAAAK0njC1bUNBJyHVa3RZhmki2LKZI%3Dho3epZaYUM5KkRbFSERPAUmqI7Ycwqwlq1E7KS7FOsgkUuuypr"

consumer_key <- api_key
consumer_secret <-api_secret_key
access_token <- "2311731293-riYHv8BowECPCsqYsZBGeAPzwatxWuXokScWDfj"
access_secret <- "dcp3hitpg2BbY7NQd2u6UsDUrAumQPTPaXRtDm1h8JAGy"

#twitteR
setup_twitter_oauth(consumer_key, consumer_secret, access_token, access_secret)

#rtweet
twitter_token <- create_token(
   app = "covid-19 mental health",
    consumer_key = api_key,
    consumer_secret = api_secret_key,
   access_token =access_token ,
   access_secret = access_secret)
```



- Topic modeling, unsupervised NLP like clustering 
- Sentiment analysis

```{r}
# fn_twitter <- searchTwitter("#covid exclude:retweets",n=2000,lang="en")
# 
# #January 31 â€” WHO Issues Global Health Emergency
# fn_twitter <- search_twitter_and_store("#covid exclude:retweets", since='2020-01-31', until='2020-02-01',lang="en")

# 1. exclude retweets
# 2. include word: covid
since <- "2020-01-31"
until <- "2020-02-02"

rt <- search_tweets(q="covid", n=100, type = "recent", include_rts = FALSE, since=since, until= until, lang = "en")


fn_twitter_df <- twListToDF(fn_twitter) # Convert to data frame

tweet_words <- fn_twitter_df %>% 
  select(id, text) %>% 
  unnest_tokens(word,text)


tweet_words %>% 
  count(word,sort=T) %>% 
  slice(1:20) %>% 
  ggplot(aes(x = reorder(word, 
    n, function(n) -n), y = n)) + geom_bar(stat = "identity") + theme(axis.text.x = element_text(angle = 60, 
    hjust = 1)) + xlab("")
```

# stop words
```{r}
# Create a list of stop words: a list of words that are not worth including
my_stop_words <- stop_words %>% 
  select(-lexicon) %>% 
  bind_rows(data.frame(word = c("https", "t.co", "rt", "19")))

tweet_words_interesting <- tweet_words %>% 
  anti_join(my_stop_words)

tweet_words_interesting %>% 
  group_by(word) %>% 
  tally(sort=TRUE) %>% 
  slice(1:25) %>% 
  ggplot(aes(x = reorder(word, 
    n, function(n) -n), y = n)) + geom_bar(stat = "identity") + theme(axis.text.x = element_text(angle = 60, 
    hjust = 1)) + xlab("")
```

# bigram
```{r}
bigrams <- fn_twitter_df %>%
  unnest_tokens(bigram, text, token = "ngrams", n = 2)%>%
  count(bigram, sort=T) %>%
  filter(n > 1)

trigrams <- fn_twitter_df %>%
  unnest_tokens(bigram, text, token = "ngrams", n = 3)%>%
  count(bigram, sort=T) %>%
  filter(n > 1)
```

```{r}
library()
get_sentiments("nrc")
install.packages("nrc")
```

# sentiment
```{r}
library(loughran)
get_sentiments("loughran")%>%
  count(sentiment)

```

